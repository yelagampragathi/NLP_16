{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yelagampragathi/NLP_16/blob/main/CRAZYCATS_ASS_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY6PhnSLmTQy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "qCaclFrSory7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/Indian language community chatbot.csv'  # Update this path with the actual path of your transcribed dataset"
      ],
      "metadata": {
        "id": "zm9wR9RZozoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read CSV with delimiter issues handled"
      ],
      "metadata": {
        "id": "ym9SmIT9o8vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(dataset_path, delimiter='|', skipinitialspace=True)"
      ],
      "metadata": {
        "id": "5hWprv_po9rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean up column names"
      ],
      "metadata": {
        "id": "e761_Y8gpD2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.strip()\n",
        "df.columns = df.columns.str.replace('|', '').str.strip()"
      ],
      "metadata": {
        "id": "AnieDtctpEmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display cleaned column names"
      ],
      "metadata": {
        "id": "ptWEWiJPpJ8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cleaned columns:\", df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu4cDIZRpKsK",
        "outputId": "8823c8ee-4756-4313-a3c7-d932702cbfd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned columns: Index(['Unnamed: 0', 'ID', 'English Text', 'Telugu Answer', 'Hindi Answer',\n",
            "       'Tamil Answer', 'Malayalam Answer', ',,,,,,,,'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fill missing values (if any) with an empty string or appropriate value"
      ],
      "metadata": {
        "id": "4HScheeypQ2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna('', inplace=True)"
      ],
      "metadata": {
        "id": "YEGTH76spRgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic text cleaning function"
      ],
      "metadata": {
        "id": "QyRua-bppWtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.strip()  # Remove leading and trailing spaces\n",
        "    return text"
      ],
      "metadata": {
        "id": "yhbl8FHipXQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply text cleaning to relevant columns"
      ],
      "metadata": {
        "id": "gz62WH4Kpcbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['English Text'] = df['English Text'].apply(clean_text)\n",
        "df['Telugu Answer'] = df['Telugu Answer'].apply(clean_text)\n",
        "df['Hindi Answer'] = df['Hindi Answer'].apply(clean_text)\n",
        "df['Tamil Answer'] = df['Tamil Answer'].apply(clean_text)\n",
        "df['Malayalam Answer'] = df['Malayalam Answer'].apply(clean_text)"
      ],
      "metadata": {
        "id": "CmN435YFpdNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to get translations"
      ],
      "metadata": {
        "id": "aiZRhtTqpirP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_translations(question):\n",
        "    row = df[df['English Text'] == question]\n",
        "    if not row.empty:\n",
        "        return {\n",
        "            'Telugu': row['Telugu Answer'].values[0],\n",
        "            'Hindi': row['Hindi Answer'].values[0],\n",
        "            'Tamil': row['Tamil Answer'].values[0],\n",
        "            'Malayalam': row['Malayalam Answer'].values[0]\n",
        "        }\n",
        "    else:\n",
        "        return 'Question not found'"
      ],
      "metadata": {
        "id": "pN7Fy4FGpjOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example usage: Get translations"
      ],
      "metadata": {
        "id": "_LfGBidsppq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'What is your name?'\n",
        "translations = get_translations(question)\n",
        "print(f\"Translations for '{question}': {translations}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ks6F6EFpqXN",
        "outputId": "ffaae498-50e1-458b-937c-432133d7759d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translations for 'What is your name?': {'Telugu': 'నా పేరు రామ్.', 'Hindi': 'मेरा नाम राम है।', 'Tamil': 'என் பெயர் ராம்.', 'Malayalam': 'എന്റെ പേര് രാം.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing text processing tasks as per assignment"
      ],
      "metadata": {
        "id": "oVB0C-aZpv8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tokenization"
      ],
      "metadata": {
        "id": "61Xp3awHp0SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NhDjsUqp03o",
        "outputId": "eaf46f9b-bf77-4128-90c1-daee6d612419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "hNmqwZy9qKDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize example text"
      ],
      "metadata": {
        "id": "qLQ7qteoqN0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = df['English Text'].iloc[0]  # Get an example text from the dataset\n",
        "tokens = word_tokenize(example_text)\n",
        "print(f\"Tokens: {tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zfo_MvHqOi2",
        "outputId": "94ba910e-f45d-45df-fcaa-d34334bd41f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['What', 'is', 'your', 'name', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Stemming\n",
        "# Stem words from an example text"
      ],
      "metadata": {
        "id": "VKYBN-AOq2sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = df['English Text'].iloc[0]  # Get example text from the dataset\n",
        "tokens = word_tokenize(example_text)  # Tokenize the example text\n",
        "stemmer = PorterStemmer()\n",
        "stems = [stemmer.stem(word) for word in tokens]  # Apply stemming to the tokens\n",
        "print(f\"Stems: {stems}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkxkIMXrq3hA",
        "outputId": "a94db37f-40ca-4a18-bb22-0f95e56ea82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stems: ['what', 'is', 'your', 'name', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Word Representation\n",
        "# Represent words in the English Text column"
      ],
      "metadata": {
        "id": "ltyt9065rjBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['English Text'].tolist()  # Convert the 'English Text' column to a list of texts\n",
        "vectorizer = CountVectorizer()  # Initialize CountVectorizer\n",
        "word_vectors = vectorizer.fit_transform(texts).toarray()  # Fit and transform the texts\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "1n8syBqPrju_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the results"
      ],
      "metadata": {
        "id": "Qdc10XXUsPvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample of cleaned English Text data:\")\n",
        "print(df['English Text'].head())\n",
        "print(\"\\nSample of cleaned Telugu Answer data:\")\n",
        "print(df['Telugu Answer'].head())\n",
        "print(\"\\nSample of cleaned Hindi Answer data:\")\n",
        "print(df['Hindi Answer'].head())\n",
        "print(\"\\nSample of cleaned Tamil Answer data:\")\n",
        "print(df['Tamil Answer'].head())\n",
        "print(\"\\nSample of cleaned Malayalam Answer data:\")\n",
        "print(df['Malayalam Answer'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8PrDKWPsQgy",
        "outputId": "8e9b8460-9555-44d6-f7a1-359e4f54a0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of cleaned English Text data:\n",
            "0              What is your name?\n",
            "1              Where do you live?\n",
            "2                How old are you?\n",
            "3    What do you do for a living?\n",
            "4    What is your favorite color?\n",
            "Name: English Text, dtype: object\n",
            "\n",
            "Sample of cleaned Telugu Answer data:\n",
            "0                          నా పేరు రామ్.\n",
            "1              నేను హైదరాబాద్‌లో ఉంటాను.\n",
            "2            నేను 25 సంవత్సరాలు ఉన్నాను.\n",
            "3    నేను ఒక ఇంజనీర్‌గానుగా పనిచేస్తాను.\n",
            "4                 నా ప్రియమైన రంగు నీలం.\n",
            "Name: Telugu Answer, dtype: object\n",
            "\n",
            "Sample of cleaned Hindi Answer data:\n",
            "0              मेरा नाम राम है।\n",
            "1    मैं हैदराबाद में रहता हूँ।\n",
            "2            मैं 25 साल का हूँ।\n",
            "3          मैं एक इंजीनियर हूँ।\n",
            "4     मेरा पसंदीदा रंग नीला है।\n",
            "Name: Hindi Answer, dtype: object\n",
            "\n",
            "Sample of cleaned Tamil Answer data:\n",
            "0                    என் பெயர் ராம்.\n",
            "1    நான் ஹைதராபாத்தில் வசிக்கிறேன்.\n",
            "2                      நான் 25 வயது.\n",
            "3                நான் ஒரு பொறியாளர்.\n",
            "4        எனக்கு பிடித்த நிறம் நீலம்.\n",
            "Name: Tamil Answer, dtype: object\n",
            "\n",
            "Sample of cleaned Malayalam Answer data:\n",
            "0                    എന്റെ പേര് രാം.\n",
            "1      ഞാൻ ഹൈദരാബാദിൽ താമസിക്കുന്നു.\n",
            "2               എനിക്ക് 25 വയസ്സാണ്.\n",
            "3              ഞാൻ ഒരു എൻജിനീയർ ആണ്.\n",
            "4    എനിക്ക് ഇഷ്ടമുള്ള നിറം നീലമാണ്.\n",
            "Name: Malayalam Answer, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example: Word Representation using the 'English Text' column"
      ],
      "metadata": {
        "id": "5bi1LBEMtZYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize CountVectorizer with additional parameters if needed"
      ],
      "metadata": {
        "id": "t0lVK_P3thzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['English Text'].tolist()  # Extract English Text for vectorization\n",
        "vectorizer = CountVectorizer()\n",
        "word_vectors = vectorizer.fit_transform(texts).toarray()\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(f\"Word Vectors:\\n{word_vectors}\")\n",
        "print(f\"Feature Names:\\n{feature_names}\")"
      ],
      "metadata": {
        "id": "UouH7Tzw7ruh",
        "outputId": "93143b07-9bda-499d-ee18-e1a53b69c637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Vectors:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]]\n",
            "Feature Names:\n",
            "['activity' 'adventures' 'animal' 'animals' 'any' 'app' 'are' 'beach'\n",
            " 'best' 'book' 'books' 'can' 'car' 'city' 'coffee' 'color' 'cook'\n",
            " 'cooking' 'countryside' 'cream' 'cuisine' 'dancing' 'day' 'dessert'\n",
            " 'destination' 'did' 'do' 'dream' 'drink' 'drive' 'drives' 'english'\n",
            " 'enjoy' 'exercise' 'favorite' 'festival' 'flower' 'food' 'for' 'friend'\n",
            " 'fruit' 'gadget' 'games' 'gardening' 'genre' 'going' 'have' 'hobby'\n",
            " 'holiday' 'hometown' 'how' 'ice' 'in' 'indoor' 'instruments' 'is' 'job'\n",
            " 'languages' 'like' 'listening' 'live' 'living' 'long' 'married' 'media'\n",
            " 'meditate' 'morning' 'movie' 'movies' 'music' 'name' 'of' 'old' 'or'\n",
            " 'out' 'outdoor' 'outfit' 'painting' 'person' 'pet' 'pets' 'photography'\n",
            " 'picnics' 'place' 'platform' 'play' 'playing' 'prefer' 'profession'\n",
            " 'reading' 'regularly' 'season' 'selfies' 'shows' 'siblings' 'snack'\n",
            " 'snacks' 'social' 'speak' 'spicy' 'sport' 'sports' 'study' 'subject'\n",
            " 'sweet' 'taking' 'tea' 'technology' 'the' 'time' 'to' 'travel' 'tv'\n",
            " 'vegetable' 'visit' 'watch' 'weather' 'website' 'week' 'what' 'where'\n",
            " 'work' 'working' 'writing' 'year' 'you' 'your' 'ஆம' 'கள' 'கழ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Representation (example sentences for illustration)"
      ],
      "metadata": {
        "id": "f7MEzdAO8xqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_vectors = vectorizer.transform(texts).toarray()  # Use transform instead of fit_transform to use the same vectorizer\n",
        "print(f\"Sentence Vectors:\\n{sentence_vectors}\")\n",
        "print(f\"Feature Names:\\n{feature_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxrJTuwS819s",
        "outputId": "718c2255-c70f-4a88-b383-0ac6ffcdeba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Vectors:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Feature Names:\n",
            "['activity' 'adventures' 'animal' 'animals' 'any' 'app' 'are' 'beach'\n",
            " 'best' 'book' 'books' 'can' 'car' 'city' 'coffee' 'color' 'cook'\n",
            " 'cooking' 'countryside' 'cream' 'cuisine' 'dancing' 'day' 'dessert'\n",
            " 'destination' 'did' 'do' 'dream' 'drink' 'drive' 'drives' 'english'\n",
            " 'enjoy' 'exercise' 'favorite' 'festival' 'flower' 'food' 'for' 'friend'\n",
            " 'fruit' 'gadget' 'games' 'gardening' 'genre' 'going' 'have' 'hobby'\n",
            " 'holiday' 'hometown' 'how' 'ice' 'in' 'indoor' 'instruments' 'is' 'job'\n",
            " 'languages' 'like' 'listening' 'live' 'living' 'long' 'married' 'media'\n",
            " 'meditate' 'morning' 'movie' 'movies' 'music' 'name' 'of' 'old' 'or'\n",
            " 'out' 'outdoor' 'outfit' 'painting' 'person' 'pet' 'pets' 'photography'\n",
            " 'picnics' 'place' 'platform' 'play' 'playing' 'prefer' 'profession'\n",
            " 'reading' 'regularly' 'season' 'selfies' 'shows' 'siblings' 'snack'\n",
            " 'snacks' 'social' 'speak' 'spicy' 'sport' 'sports' 'study' 'subject'\n",
            " 'sweet' 'taking' 'tea' 'technology' 'the' 'time' 'to' 'travel' 'tv'\n",
            " 'vegetable' 'visit' 'watch' 'weather' 'website' 'week' 'what' 'where'\n",
            " 'work' 'working' 'writing' 'year' 'you' 'your' 'ஆம' 'கள' 'கழ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the cleaned dataset"
      ],
      "metadata": {
        "id": "viOhGOIR9a2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_dataset_path = '/content/Indian language community chatbot.csv'  # Update this path as needed\n",
        "df.to_csv(cleaned_dataset_path, index=False)\n",
        "print(f\"Cleaned dataset saved to {cleaned_dataset_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5qKEuBp9bar",
        "outputId": "97497cfb-483c-4d6f-989e-062d44f7c1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset saved to /content/Indian language community chatbot.csv\n"
          ]
        }
      ]
    }
  ]
}